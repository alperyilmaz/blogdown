[{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536440400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536440400,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"/tutorial/","publishdate":"2018-09-09T00:00:00+03:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536440400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536440400,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"/tutorial/example/","publishdate":"2018-09-09T00:00:00+03:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":[],"categories":null,"content":"Click on the Slides button above to view the built-in slides feature.\n Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using url_slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1483218000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483218000,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00+03:00","relpermalink":"/talk/example/","section":"talk","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":[],"content":"After starting to use the bash, you quickly realize bash history is an invaluable asset. You can quickly search and find a previous command in order to remember when and what you have done. I was using a primitive way to archive the history with which I accumulated history of commands since 2008. The primitive setup has two parts. First part is a cron job:\n0 13 3,11,24 * * /bin/cat ~/.bash_history \u0026gt; ~/.history_backup_`date +\\%Y\\%m\\%d`  This cron job line means: on 3rd, 11th and 24th of each month at 1pm dump contents of .bash_history file to history backup file. By time, I ended up with 1-2 files per month.\nSecond part is couple bash functions to merge the archive.\noldhistory(){ for file in /home/alper/.history_backup_20*; do cat $file; echo; done | perl -ne 'if (/^#([0-9]{10}$)/){my $nextline=\u0026lt;\u0026gt;; $hash{$1}=$nextline }else{next}; END{print map { $hash{$_} } sort keys %hash}'; } oldhistory-time(){ for file in /home/alper/.history_backup_20*; do cat $file; echo; done | perl -ne 'if (/^#([0-9]{10}$)/){ my $nextline=\u0026lt;\u0026gt;; $hash{$1}=$nextline }else{next}; END{print map {scalar localtime($_).\u0026quot;\\t\u0026quot;.$hash{$_}} sort keys %hash}'; }  However, just recently I noticed that the bash history file is trimmed and contained only 10 days of worth commands. Luckily, I recovered a backup of .bash_history file and didn\u0026rsquo;t lose much data. But, it was a wakeup call, my primitive system is prone to lose data without a notice. So, I started searching for a better solution to archive bash history.\nWhen I search online I first came across this post. And then carried on searching and didn\u0026rsquo;t find anything that intrigues me. I also searched Github after which I got couple of aha moments. Bashhub can save your bash history in the cloud. That was very interesting and useful but I didn\u0026rsquo;t like the third party keeping the commands. There were couple more projects offering nice UI or advanced features (sqlite database for instance), such as history, hstr, bash-history-sqlite.\nFinally, I got a good idea from this blog. Now, I\u0026rsquo;m testing this method and hoping that it would work with less problems.\nexport PROMPT_COMMAND='history -a; history -n; if [ \u0026quot;$(id -u)\u0026quot; -ne 0 ]; then echo -e \u0026quot;$(date \u0026quot;+%Y-%m-%d.%H:%M:%S\u0026quot;)\\t$(hostname)\\t$(pwd)\\t$(history -p \\!-1)\u0026quot; \u0026gt;\u0026gt; ~/.logs/bash-history-$(hostname)-$(date \u0026quot;+%Y-%m-%d\u0026quot;).log; fi'   Update (2017-05-26): This code causes problem with screen. Within screen the command is not printed out and written correctly into bash-history file.\n ","date":1474925165,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1474925165,"objectID":"d25804cc703cdcb415432d0e2b54e4a3","permalink":"/blog/2016/09/27/eternal-bash-history/","publishdate":"2016-09-27T00:26:05+03:00","relpermalink":"/blog/2016/09/27/eternal-bash-history/","section":"post","summary":"After starting to use the bash, you quickly realize bash history is an invaluable asset. You can quickly search and find a previous command in order to remember when and what you have done. I was using a primitive way to archive the history with which I accumulated history of commands since 2008. The primitive setup has two parts. First part is a cron job:\n0 13 3,11,24 * * /bin/cat ~/.","tags":["commandline"],"title":"Eternal bash history","type":"post"},{"authors":null,"categories":null,"content":"From time to time, I had many terminal tabs open and wanted to see the list of terminals along with working folder names. Finally, I fed up with the issue tried to find a solution. After fiddling with some code, here\u0026rsquo;s the function that I added to .bashrc file\ntty-list() { ps aux --sort=start_time | grep \u0026quot;pts/\u0026quot; | grep [b]ash | awk -F\u0026quot; +\u0026quot; '{print $2\u0026quot;\\t\u0026quot;$7}' | while read PID PTS; do echo -n -e \u0026quot;$PTS\u0026quot;\u0026quot;\\t\u0026quot;; readlink -f /proc/$PID/cwd; done ; }  In terminal, tty-list command lists the pts number and working folder name as shown below:\npts/3\t/home/alper pts/6\t/home/alper pts/7\t/home/alper/.logs pts/8\t/home/alper/tmp pts/9\t/home/alper/Documents/blog-github/website pts/9 /home/alper/Documents/blog-github/website  The list is in order of opening the tabs. As you notice, last two lines are duplicate because when you issue the function there\u0026rsquo;s while loop and I\u0026rsquo;m guessing it\u0026rsquo;s running in a subshell so the terminal you run the function is counted twice.\n","date":1473930000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473930000,"objectID":"ace9f9ceaf1e026d5f2d2ee151e8e8e3","permalink":"/blog/2016/09/15/list-of-terminals-with-working-folder-names/","publishdate":"2016-09-15T12:00:00+03:00","relpermalink":"/blog/2016/09/15/list-of-terminals-with-working-folder-names/","section":"post","summary":"From time to time, I had many terminal tabs open and wanted to see the list of terminals along with working folder names. Finally, I fed up with the issue tried to find a solution. After fiddling with some code, here\u0026rsquo;s the function that I added to .bashrc file\ntty-list() { ps aux --sort=start_time | grep \u0026quot;pts/\u0026quot; | grep [b]ash | awk -F\u0026quot; +\u0026quot; '{print $2\u0026quot;\\t\u0026quot;$7}' | while read PID PTS; do echo -n -e \u0026quot;$PTS\u0026quot;\u0026quot;\\t\u0026quot;; readlink -f /proc/$PID/cwd; done ; }  In terminal, tty-list command lists the pts number and working folder name as shown below:","tags":["commandline"],"title":"List of terminals with working folder names","type":"post"},{"authors":null,"categories":null,"content":"After going thru a long list of themes, the following themes have some or all capabilities I\u0026rsquo;d like to have in a theme:\nhttp://www.hossainmohdfaysal.com/hmfaysal-omega-theme/\nhttps://github.com/holman/left might not be as pretty as https://zachholman.com/\nhttp://chrisanthropic.github.io/slim-pickins-jekyll-theme/\nhttps://rohanchandra.github.io/type-theme/\nhttp://aronbordin.com/neo-hpstr-jekyll-theme/\nhttp://bloginn-jekyll.justgoodthemes.com/\nhttp://dongchuan.github.io/\nhttp://biomadeira.github.io/jasper/\nhttp://phlow.github.io/feeling-responsive/\nNot sure if this one has a downloadable theme: https://mademistakes.com/articles/jekyll-style-guide/\nHighly modified theme: http://willkoehler.net/2014/08/26/save-50-hours-setting-up-your-jekyll-blog.html\n","date":1463695857,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1463695857,"objectID":"29e24a695a75f0bd449dfc0989c3c7a4","permalink":"/blog/2016/05/20/jekyll-themes-i-want-to-try/","publishdate":"2016-05-20T01:10:57+03:00","relpermalink":"/blog/2016/05/20/jekyll-themes-i-want-to-try/","section":"post","summary":"After going thru a long list of themes, the following themes have some or all capabilities I\u0026rsquo;d like to have in a theme:\n","tags":["jekyll"],"title":"Jekyll themes I want to try","type":"post"},{"authors":null,"categories":null,"content":"","date":1461704400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461704400,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00+03:00","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461704400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461704400,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00+03:00","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":[],"categories":null,"content":" Academic makes it easy to create a beautiful website for free using Markdown. Customize anything on your site with widgets, themes, and language packs.\nFollow our easy step by step guide to learn how to build your own free website with Academic. Check out the personal demo or the business demo of what you\u0026rsquo;ll get in less than 10 minutes.\n View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an Academic sticker Wear the T-shirt   \nKey features:\n Easily manage various content including homepage, blog posts, publications, talks, and projects Extensible via color themes and widgets/plugins Write in Markdown for easy formatting and code highlighting, with LaTeX for mathematical expressions Social/academic network linking, Google Analytics, and Disqus comments Responsive and mobile friendly Simple and refreshing one page design Multilingual and easy to customize  Color Themes Academic is available in different color themes and font themes.\n         Ecosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Quick install using your web browser  Install Academic with Netlify  Netlify will provide you with a customizable URL to access your new site  On GitHub, go to your newly created academic-kickstart repository and edit config.toml to personalize your site. Shortly after saving the file, your site will automatically update Read the Quick Start Guide to learn how to add Markdown content. For inspiration, refer to the Markdown content which powers the Demo  Install with Git Prerequisites:\n Download and install Git Download and install Hugo   Fork the Academic Kickstart repository and clone your fork with Git:\ngit clone https://github.com/sourcethemes/academic-kickstart.git My_Website  Note that if you forked Academic Kickstart, the above command should be edited to clone your fork, i.e. replace sourcethemes with your GitHub username.\n Initialize the theme:\ncd My_Website git submodule update --init --recursive   Install with ZIP  Download and extract Academic Kickstart Download and extract the Academic theme to the themes/academic/ folder from the above step  Install with RStudio View the guide to installing Academic with RStudio\nQuick start  If you installed on your computer, view your new website by running the following command:\nhugo server  Now visit localhost:1313 and your new Academic powered website will appear. Otherwise, if using Netlify, they will provide you with your URL.\n Read the Quick Start Guide to learn how to add Markdown content, customize your site, and deploy it. For inspiration, refer to the Markdown content which powers the Demo\n Build your site by running the hugo command. Then host it for free using Github Pages or Netlify (refer to the first installation method). Alternatively, copy the generated public/ directory (by FTP, Rsync, etc.) to your production web server (such as a university\u0026rsquo;s hosting service).\n  Updating Feel free to star the project on Github to help keep track of updates and check out the release notes prior to updating your site.\nBefore updating the framework, it is recommended to make a backup of your entire website directory (or at least your themes/academic directory) and record your current version number.\nBy default, Academic is installed as a Git submodule which can be updated by running the following command:\ngit submodule update --remote --merge  Check out the update guide for full instructions and alternative methods.\nFeedback \u0026amp; Contributing Please use the issue tracker to let me know about any bugs or feature requests, or alternatively make a pull request.\nFor support, head over to the Hugo discussion forum.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461099600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515790800,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"/blog/2016/04/20/academic-the-website-designer-for-hugo/","publishdate":"2016-04-20T00:00:00+03:00","relpermalink":"/blog/2016/04/20/academic-the-website-designer-for-hugo/","section":"post","summary":"Create a beautifully simple website or blog in under 10 minutes.","tags":["Academic"],"title":"Academic: the website designer for Hugo","type":"post"},{"authors":["GA Cushen"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1441054800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441054800,"objectID":"d77fa4a74076ffcd7ca6c21cfc27a4b2","permalink":"/publication/person-re-id/","publishdate":"2015-09-01T00:00:00+03:00","relpermalink":"/publication/person-re-id/","section":"publication","summary":"Person re-identification is a critical security task for recognizing a person across spatially disjoint sensors. Previous work can be computationally intensive and is mainly based on low-level cues extracted from RGB data and implemented on a PC for a fixed sensor network (such as traditional CCTV). We present a practical and efficient framework for mobile devices (such as smart phones and robots) where high-level semantic soft biometrics are extracted from RGB and depth data. By combining these cues, our approach attempts to provide robustness to noise, illumination, and minor variations in clothing. This mobile approach may be particularly useful for the identification of persons in areas ill-served by fixed sensors or for tasks where the sensor position and direction need to dynamically adapt to a target. Results on the BIWI dataset are preliminary but encouraging. Further evaluation and demonstration of the system will be available on our website.","tags":[],"title":"A Person Re-Identification System For Mobile Devices","type":"publication"},{"authors":null,"categories":["R"],"content":" R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932  Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA )  Figure 1: A fancy pie chart.   ","date":1437703994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437703994,"objectID":"10065deaa3098b0da91b78b48d0efc71","permalink":"/blog/2015/07/23/hello-r-markdown/","publishdate":"2015-07-23T21:13:14-05:00","relpermalink":"/blog/2015/07/23/hello-r-markdown/","section":"post","summary":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown","type":"post"},{"authors":["GA Cushen","MS Nixon"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1372626000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372626000,"objectID":"2b4d919e3cf73dfcd0063c88fe01cb00","permalink":"/publication/clothing-search/","publishdate":"2013-07-01T00:00:00+03:00","relpermalink":"/publication/clothing-search/","section":"publication","summary":"We present a mobile visual clothing search system whereby a smart phone user can either choose a social networking photo or take a new photo of a person wearing clothing of interest and search for similar clothing in a retail database. From the query image, the person is detected, clothing is segmented, and clothing features are extracted and quantized. The information is sent from the phone client to a server, where the feature vector of the query image is used to retrieve similar clothing products from online databases. The phone's GPS location is used to re-rank results by retail store location. State of the art work focuses primarily on the recognition of a diverse range of clothing offline and pays little attention to practical applications. Evaluated on a challenging dataset, the system is relatively fast and achieves promising results.","tags":[],"title":"Mobile visual clothing search","type":"publication"},{"authors":null,"categories":null,"content":"Here\u0026rsquo;s the matrix that we\u0026rsquo;ll be using:\n$ paste \u0026lt;(seq 1 5) \u0026lt;(seq 12 16) 1\t12 2\t13 3\t14 4\t15 5\t16  Now, let\u0026rsquo;s use a perl one-liner with nested maps to transpose the matrix:\n$ paste \u0026lt;(seq 1 5) \u0026lt;(seq 12 16) | perl -ane 'push @matrix,[@F]; END { print join \u0026quot;\\n\u0026quot;,map {$row=$_; join\u0026quot;\\t\u0026quot;,map { $matrix[$_][$row]} 0 .. $#matrix } 0 .. $#{$matrix[0]}; print \u0026quot;\\n\u0026quot; }' 1\t2\t3\t4\t5 12\t13\t14\t15\t16  I got the idea from this blog post, but I slightly modified it so that you don\u0026rsquo;t need to make a copy of the transposed array (to save memory)\n","date":1310031217,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1310031217,"objectID":"fd8b7ad3bc09fe5001a663e7f827c162","permalink":"/blog/2011/07/07/transpose-a-matrix-with-perl-nested-map/","publishdate":"2011-07-07T09:33:37Z","relpermalink":"/blog/2011/07/07/transpose-a-matrix-with-perl-nested-map/","section":"post","summary":"Here\u0026rsquo;s the matrix that we\u0026rsquo;ll be using:\n$ paste \u0026lt;(seq 1 5) \u0026lt;(seq 12 16) 1\t12 2\t13 3\t14 4\t15 5\t16  Now, let\u0026rsquo;s use a perl one-liner with nested maps to transpose the matrix:\n$ paste \u0026lt;(seq 1 5) \u0026lt;(seq 12 16) | perl -ane 'push @matrix,[@F]; END { print join \u0026quot;\\n\u0026quot;,map {$row=$_; join\u0026quot;\\t\u0026quot;,map { $matrix[$_][$row]} 0 .. $#matrix } 0 .. $#{$matrix[0]}; print \u0026quot;\\n\u0026quot; }' 1\t2\t3\t4\t5 12\t13\t14\t15\t16  I got the idea from this blog post, but I slightly modified it so that you don\u0026rsquo;t need to make a copy of the transposed array (to save memory)","tags":["commandline","one-liner","perl"],"title":"Transpose a matrix with perl nested map","type":"post"},{"authors":null,"categories":null,"content":"Let\u0026rsquo;s assume you have an array of numbers and you want to extract intervals from this array. For example, from such an array: 2,3,4,5,8,9,10,11,12,15,18,19,20 you should be getting (2-5), (8-12), (18-20) as intervals.\nMore bioinformatic case: Let\u0026rsquo;s assume you ran samtools pileup format and want to extract intervals from the genomic coordinates that has at least one hit.\nThe following one-liner will give you what you want: (I used seq to generate array of numbers and concatenated multiple seq)\ncat \u0026lt;(seq 3 23) \u0026lt;(echo 25) \u0026lt;(seq 40 50) | perl -ne 'BEGIN{our $i=1}; chomp ; if(($_ - (${$hash-\u0026gt;{$i-1}}[-1]))==1){push @{$hash-\u0026gt;{$i-1}},$_}else{push @{$hash-\u0026gt;{$i++}},$_}; END {print join\u0026quot;\\n\u0026quot;, map {${$hash-\u0026gt;{$_}}[0].\u0026quot;\\t\u0026quot;.${$hash-\u0026gt;{$_}}[-1]} grep { scalar(@{$hash-\u0026gt;{$_}}) \u0026gt; 1} sort {$a \u0026lt;=\u0026gt; $b} keys %$hash; print \u0026quot;\\n\u0026quot;}'  And the result is:\n3\t23 40\t50  map was used to get first and last element of array, grep is used to filter out arrays that has less than 2 elements.\n","date":1309157882,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1309157882,"objectID":"708350ac2b558e5719f3885ee588e9c3","permalink":"/blog/2011/06/27/extract-intervals-from-an-array-of-numbers/","publishdate":"2011-06-27T06:58:02Z","relpermalink":"/blog/2011/06/27/extract-intervals-from-an-array-of-numbers/","section":"post","summary":"Let\u0026rsquo;s assume you have an array of numbers and you want to extract intervals from this array. For example, from such an array: 2,3,4,5,8,9,10,11,12,15,18,19,20 you should be getting (2-5), (8-12), (18-20) as intervals.\nMore bioinformatic case: Let\u0026rsquo;s assume you ran samtools pileup format and want to extract intervals from the genomic coordinates that has at least one hit.\n","tags":["commandline","one-liner","perl"],"title":"Extract intervals from an array of numbers","type":"post"},{"authors":null,"categories":null,"content":"Soon after SAM/BAM format became standard for short-read alignment softwares, high caliber tools have been emerging that can process the widely accepted format. bedtools is one of them and it\u0026rsquo;s easy to use and flexible. Most importantly you can integrate it with commandline pipes.\nIn this post, I\u0026rsquo;ll be describing how to extract upstream region sequences with the help of bedtools. I\u0026rsquo;ll be using the following files in my sample:\nFile1: small-chr-genes.bed (holds locations of genes)\n1\t10\t20\tgene1\t0\t+ 1\t40\t50\tgene2\t0\t-  File2: small-chr.fa (genome sequence file)\n\u0026gt;1 GCGACTACGACTACAGCACTACGACATCAGCACTACGACT ACGACTACGACATCACGACACACGACGACATCACGACTAC  File3: small-chr.genome (genome file which contains name and length of each chromosome)\n1\t80  The one-liner below extracts 5 basepairs upstream region for each gene and slopBed takes care of strand issues (reverse complement of extracted sequence if gene is on negative strand) and genome size issues (trim the extracted sequence if gene is close to beginning or end of chromosome).\nslopBed -i small-chr-genes.bed -g small-chr.genome -l 5 -r 0 -s | perl -ane '($F[5] eq \u0026quot;+\u0026quot;)? $F[2]=$F[1] : $F[1]=$F[2]; print join\u0026quot;\\t\u0026quot;,@F;print\u0026quot;\\n\u0026quot;' | slopBed -i stdin -g small-chr.genome -l 0 -r 5 -s | fastaFromBed -fi small-chr.fa -bed stdin -fo stdout -name -s  The output looks like this:\n\u0026gt;gene1 TACGA \u0026gt;gene2 TGATG  Let me try to explain how it works, first I extend each gene 5 basepair to its upstream. Then I mark the beginning of the extended region by converting it into single nucleotide region. I use slopBed again, to extend from the mark in opposite direction for 5 basepairs. Now we have the upstream region start and end coordinates, and by the help of fastaFromBed, the upstream region sequence was extracted from genome sequence.\nbedtools has a tool named subtractBed and I was thinking that combination of slopBed, subtractBed and fastaFromBed should be the solution. However, probably due to genes that are overlapping, subtracting gene region from extended region didn\u0026rsquo;t work as well as I expected. That\u0026rsquo;s why I integrated a perl one-liner to take care of subtracting the gene region from extended region.\nUpdate : bedtools developer Aaron Quinlan was kind enough to develop a new tool to accomplish the task described above. \u0026ldquo;flankBed\u0026rdquo; does exactly what is described above and it\u0026rsquo;s much simpler. Here\u0026rsquo;s the flankBed equivalent of extracting upstream regions:\nflankBed -i small-chr-genes.bed -g small-chr.genome -l 5 -r 0 -s | fastaFromBed -fi small-chr.fa -bed stdin -fo stdout -name -s  ","date":1299400836,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1299400836,"objectID":"e5410ea86f4a22560b3be63eb25f0842","permalink":"/blog/2011/03/06/extract-upstream-region-sequence-with-bedtools/","publishdate":"2011-03-06T08:40:36Z","relpermalink":"/blog/2011/03/06/extract-upstream-region-sequence-with-bedtools/","section":"post","summary":"Soon after SAM/BAM format became standard for short-read alignment softwares, high caliber tools have been emerging that can process the widely accepted format. bedtools is one of them and it\u0026rsquo;s easy to use and flexible. Most importantly you can integrate it with commandline pipes.\nIn this post, I\u0026rsquo;ll be describing how to extract upstream region sequences with the help of bedtools. I\u0026rsquo;ll be using the following files in my sample:","tags":["bioinformatics","one-liner","perl"],"title":"Extract upstream region sequence with bedtools","type":"post"},{"authors":null,"categories":null,"content":"In this post, I\u0026rsquo;ll demonstrate how to use gnuplot in a one-liner. We\u0026rsquo;ll use the pipe but unfortunately you cannot pipe raw data to gnuplot directly (as far as I know). The piped data should contain basic gnuplot commands on top. So, we\u0026rsquo;ll use the following template:\nvery-complicated-data-generating-commands | sed -e \u0026quot;1i\\plot '-' \u0026quot; | gnuplot -persist  If you\u0026rsquo;re interested in quickly see how this works, try something simple:\nseq 1 10 | sed -e \u0026quot;1i\\plot '-'\u0026quot; | gnuplot -persist  Before sed command, you can write as complicated as possible command to generate data and inside sed command you can put long gnuplot commands to obtain graphs. Let\u0026rsquo;s see the counts of most used 20 commands from history (mentioned in an earlier post with bar chart.\ncat ~/.bash_history|grep -v \u0026quot;^#\u0026quot; | perl -F\u0026quot;\\||\u0026lt;\\(|;|\\`|\\\\$\\(\u0026quot; -alne 'foreach (@F) { print $1 if /^.*?(\\w+)\\b/i }' | sort | uniq -c | sort -nr | head -20 | awk '{print $2\u0026quot;\\t\u0026quot;$1}' | sed -e \u0026quot;1i\\set boxwidth 0.5\\nset style fill solid noborder\\nset xtics nomirror rotate by -60\\nset format x '-%s'\\nplot '-' using 2:xticlabels(1) with boxes notitle\u0026quot; | gnuplot -persist  Resulting image looks like this:\nIf you want to save the output in png format, what you do is simply add the command set term png size 600,300 to your one-liner. I chose width 600px and height 300px as example. In this case, gnuplot prints the contents of png file to screen, so we need to direct it to a filename, as shown below:\ncat ~/.bash_history|grep -v \u0026quot;^#\u0026quot; | perl -F\u0026quot;\\||\u0026lt;\\(|;|\\`|\\\\$\\(\u0026quot; -alne 'foreach (@F) { print $1 if /^.*?(\\w+)\\b/i }' | sort | uniq -c | sort -nr | head -20 | awk '{print $2\u0026quot;\\t\u0026quot;$1}' | sed -e \u0026quot;1i\\set term png size 600,350\\nset boxwidth 0.5\\nset style fill solid noborder\\nset xtics nomirror rotate by -60\\nset format x '-%s'\\nplot '-' using 2:xticlabels(1) with boxes notitle\u0026quot; | gnuplot \u0026gt; sample_image.png  ","date":1287267204,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1287267204,"objectID":"49a52ca096ec4b11f16c381d92dfba92","permalink":"/blog/2010/10/16/plot-one-liner-generated-data-with-gnuplot/","publishdate":"2010-10-16T22:13:24Z","relpermalink":"/blog/2010/10/16/plot-one-liner-generated-data-with-gnuplot/","section":"post","summary":"In this post, I\u0026rsquo;ll demonstrate how to use gnuplot in a one-liner. We\u0026rsquo;ll use the pipe but unfortunately you cannot pipe raw data to gnuplot directly (as far as I know). The piped data should contain basic gnuplot commands on top. So, we\u0026rsquo;ll use the following template:\nvery-complicated-data-generating-commands | sed -e \u0026quot;1i\\plot '-' \u0026quot; | gnuplot -persist  If you\u0026rsquo;re interested in quickly see how this works, try something simple:","tags":["commandline","gnuplot","one-liner","visualization"],"title":"Plot one-liner generated data with gnuplot","type":"post"},{"authors":null,"categories":null,"content":"In an earlier post we learned how to use Bio::SeqIO module to process fasta files with one-liner. Let\u0026rsquo;s do more with this capability. What about selecting random sequences from a fasta file?\nTo achieve that, we\u0026rsquo;ll load the fasta file contents into a hash and then utilize the fact that rand(@array) returns index of a random element from that array.\nLet\u0026rsquo;s pick 100 random sequences from a fasta file with one-liner:\n.. fasta file stream .. | perl -MBio::SeqIO -e '$seq=Bio::SeqIO-\u0026gt;new(-fh =\u0026gt; \\*STDIN);while ($myseq=$seq-\u0026gt;next_seq){ $hash{$myseq-\u0026gt;id}=$myseq-\u0026gt;seq }; END{@ids = keys %hash; foreach (1..100){my $index=rand(@ids); print \u0026quot;\u0026gt;\u0026quot;,$ids[$index],\u0026quot;\\n\u0026quot;,$hash{$ids[$index]},\u0026quot;\\n\u0026quot; } }'  UPDATE: If this one-liner throws problem about first sequence, please indicate the format of the input. Since read ahead is not possible in a pipe, the format might not be guessed correctly. So, please update the one-liner with this: $seq=Bio::SeqIO-\u0026gt;new(-fh =\u0026gt; \\*STDIN, -format=\u0026gt;\u0026quot;fasta\u0026quot;)\n","date":1279181033,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1279181033,"objectID":"62d845b6362a07a79869be84cb2dbdd1","permalink":"/blog/2010/07/15/perl-one-liner-to-pick-random-sequences-from-fasta-file/","publishdate":"2010-07-15T08:03:53Z","relpermalink":"/blog/2010/07/15/perl-one-liner-to-pick-random-sequences-from-fasta-file/","section":"post","summary":"In an earlier post we learned how to use Bio::SeqIO module to process fasta files with one-liner. Let\u0026rsquo;s do more with this capability. What about selecting random sequences from a fasta file?\nTo achieve that, we\u0026rsquo;ll load the fasta file contents into a hash and then utilize the fact that rand(@array) returns index of a random element from that array.\nLet\u0026rsquo;s pick 100 random sequences from a fasta file with one-liner:","tags":["bioinformatics","one-liner","perl"],"title":"perl one-liner to pick random sequences from fasta file","type":"post"},{"authors":null,"categories":null,"content":"perl5i project explains itself as \u0026ldquo;Perl 5 has a lot of warts, fix as much of it as possible in one pragma\u0026rdquo;. You can run your scripts with it by including perl5i (ie, use perl5i;). Best part is, it can be run at commandline with $ perl5i -e .\nperl5i includes Autobox module which lets you call methods on primitive datatypes such as scalars and arrays (eg. \u0026ldquo;hello world\u0026rdquo;-\u0026gt;print). This feature allows constructing very compact one-liners as shown below:\nperl5i -e 'my @arr = ( 1 .. 10 ); @arr-\u0026gt;map(sub {$_ ** 4 })-\u0026gt;grep(sub { $_ \u0026gt; 3 })-\u0026gt;sum-\u0026gt;say'  Explanation: calculate to the 4th power for each element of @arr. Of those 4th power numbers, filter out the ones smaller than 3. Then sum up the new array and print the result.\nperl5i -e 'my @test=(1,2,3,4); my @compare=(2,4,6); @test-\u0026gt;intersect(\\@compare)-\u0026gt;size-\u0026gt;concat(\u0026quot;\\t\u0026quot;)-\u0026gt;print'  Explanation: Find the intersection of two arrays (assigned to new array) and add tab character to size of (intersection) array and then print it.\nperl5i -e ' my $hashref = { foo =\u0026gt; 10, bar =\u0026gt; 20, baz =\u0026gt; 30, quux =\u0026gt; 40 }; $hashref-\u0026gt;values-\u0026gt;sort-\u0026gt;join(\u0026quot;-\u0026quot;)-\u0026gt;say'  Explanation: sort the values of hash and print them by joining with \u0026ldquo;-\u0026rdquo; character.\n","date":1272325685,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1272325685,"objectID":"bb86579a161a23614b5a9532b854fee7","permalink":"/blog/2010/04/26/way-more-practical-one-liners-with-perl5i/","publishdate":"2010-04-26T23:48:05Z","relpermalink":"/blog/2010/04/26/way-more-practical-one-liners-with-perl5i/","section":"post","summary":"perl5i project explains itself as \u0026ldquo;Perl 5 has a lot of warts, fix as much of it as possible in one pragma\u0026rdquo;. You can run your scripts with it by including perl5i (ie, use perl5i;). Best part is, it can be run at commandline with $ perl5i -e .\nperl5i includes Autobox module which lets you call methods on primitive datatypes such as scalars and arrays (eg. \u0026ldquo;hello world\u0026rdquo;-\u0026gt;print). This feature allows constructing very compact one-liners as shown below:","tags":["one-liner","perl"],"title":"Way more practical one-liners with perl5i","type":"post"},{"authors":null,"categories":null,"content":"When I was trying to generate an image containing scatter-plot and a barchart with error bars, I got stuck with barchart part. There were no demos or samples that produces the desired output. So, I ended up figuring it out myself.\nBelow is the gnuplot code, data sample and the output.\nset term png size 500,400 set output \u0026quot;boxerror-test.png\u0026quot; set boxwidth 0.5 set style fill transparent solid 0.5 noborder set yrange [0:100] set xrange [0:5] plot \u0026quot;boxerror-test.data\u0026quot; using 1:2:3:xticlabels(4) w boxerror lc rgb \u0026quot;#444444\u0026quot; lw 1.5 title \u0026quot;BoxerrorTest\u0026quot;  Sample data:\n1\t25\t3\tA 2\t33\t5\tB 3\t50\t2\tC 4\t12\t0.5\tD  And the final output:\nIdeally, I was trying to plot the following data:\nA 25 3 B 33 5 C 50 2 D 12 0.5  But I wasn\u0026rsquo;t able to use first column directly as data. So, first column is actually numbers and fourth column provides the xticlabels.\nIf your gnuplot version is less than 4.4, transparency won\u0026rsquo;t work, in that case remove \u0026ldquo;transparent\u0026rdquo; from set style line.\n","date":1271255486,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1271255486,"objectID":"e447874ac2871b0996ea16ab5a31bfd9","permalink":"/blog/2010/04/14/gnuplot-boxerror-barchart-with-error-bars/","publishdate":"2010-04-14T14:31:26Z","relpermalink":"/blog/2010/04/14/gnuplot-boxerror-barchart-with-error-bars/","section":"post","summary":"When I was trying to generate an image containing scatter-plot and a barchart with error bars, I got stuck with barchart part. There were no demos or samples that produces the desired output. So, I ended up figuring it out myself.\nBelow is the gnuplot code, data sample and the output.\nset term png size 500,400 set output \u0026quot;boxerror-test.png\u0026quot; set boxwidth 0.5 set style fill transparent solid 0.5 noborder set yrange [0:100] set xrange [0:5] plot \u0026quot;boxerror-test.","tags":["gnuplot","visualization"],"title":"gnuplot boxerror, barchart with error bars","type":"post"},{"authors":null,"categories":null,"content":"Most of the \u0026ldquo;most used commands\u0026rdquo; approaches does not consider pipes and other complexities.\nThis approach considers pipes, process substitution by backticks or $() and multiple commands separated by ;\nPerl regular expression breaks up each line using | or \u0026lt;( or ; or ` or $( and picks the first word (excluding \u0026ldquo;do\u0026rdquo; in case of for loops)\nhistory | perl -F\u0026quot;\\||\u0026lt;\\(|;|\\`|\\\\$\\(\u0026quot; -alne 'foreach (@F) { print $1 if /\\b((?!do)[a-z]+)\\b/i }' | sort | uniq -c | sort -nr | head  Let\u0026rsquo;s generate a fake history file which looks like this:\n1 command file | command file | command | command 2 command \u0026lt;(command file) \u0026lt;(command file) 3 command file \u0026gt; file 4 for i in `command file`; do command file; command file; done | command 5 for i in $(command file); do command file; command file | command; done  This approach successfully counts 16 occurrences of \u0026ldquo;command\u0026rdquo; and 2 occurrences of \u0026ldquo;for\u0026rdquo;.\nNote: if you are using lots of perl one-liners, the perl commands/functions will be counted as well in this approach, since semicolon is used as a separator\n","date":1270717913,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1270717913,"objectID":"59b6944e8bc4b2ed12890e6eb95e1f37","permalink":"/blog/2010/04/08/most-used-commands-in-history/","publishdate":"2010-04-08T09:11:53Z","relpermalink":"/blog/2010/04/08/most-used-commands-in-history/","section":"post","summary":"Most of the \u0026ldquo;most used commands\u0026rdquo; approaches does not consider pipes and other complexities.\nThis approach considers pipes, process substitution by backticks or $() and multiple commands separated by ;\nPerl regular expression breaks up each line using | or \u0026lt;( or ; or ` or $( and picks the first word (excluding \u0026ldquo;do\u0026rdquo; in case of for loops)\nhistory | perl -F\u0026quot;\\||\u0026lt;\\(|;|\\`|\\\\$\\(\u0026quot; -alne 'foreach (@F) { print $1 if /\\b((?","tags":["linux","one-liner","perl"],"title":"Most used commands in history","type":"post"},{"authors":null,"categories":null,"content":"Circos is a very powerful tool to visualize different types of data (expression, homology, etc) in circular fashion.\nThe software is capable of producing very large images if desired, suitable for posters.\nActually, we can create large images for viewing online, since it\u0026rsquo;s trivial to view them with Seadragon.\nBelow is an example from Circos tutorial (I modified the config file to obtain large image) (*EDIT: Since the seadragon page was very slow to respond, I just included the embed URL*S)\n\u0026lt;script src=\u0026quot;http://seadragon.com/embed/yhz.js?width=auto\u0026amp;height=400px\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;  Original image is located here.\nPS: Author of Circos, Martin Krzywinski has more interesting software listed in his page. And his lecture notes on Data Mining and Analysis at the Command Line is worth checking.\n","date":1270226081,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1270226081,"objectID":"7aeb0916d41afb175095cc1461b0eff0","permalink":"/blog/2010/04/02/visualize-circos-images-with-seadragon/","publishdate":"2010-04-02T16:34:41Z","relpermalink":"/blog/2010/04/02/visualize-circos-images-with-seadragon/","section":"post","summary":"Circos is a very powerful tool to visualize different types of data (expression, homology, etc) in circular fashion.\nThe software is capable of producing very large images if desired, suitable for posters.\nActually, we can create large images for viewing online, since it\u0026rsquo;s trivial to view them with Seadragon.\nBelow is an example from Circos tutorial (I modified the config file to obtain large image) (*EDIT: Since the seadragon page was very slow to respond, I just included the embed URL*S)","tags":["bioinformatics","visualization"],"title":"Visualize Circos images with Seadragon","type":"post"},{"authors":null,"categories":null,"content":"Let\u0026rsquo;s assume we have a file with five columns where first column is text and rest of the columns are numeric. How can we calculate the standard deviation (or other statistical functions) with a perl one-liner?\nWe\u0026rsquo;ll use Statistics::Descriptive module.\nperl -MStatistics::Descriptive -ane 'BEGIN{our $stat = Statistics::Descriptive::Full-\u0026gt;new}; $stat-\u0026gt;add_data(@F[1..4]); print $stat-\u0026gt;standard_deviation,\u0026quot;\\n\u0026quot;; $stat-\u0026gt;clear' filename  $stat-\u0026gt;clear at the end was needed since data is added not assigned to $stat each time, so in order to prevent cumulative calculation, $stat variable should be cleared each time.\n","date":1270213552,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1270213552,"objectID":"ca275b1e878723efc5b36a306cfaf59c","permalink":"/blog/2010/04/02/one-line-statistics/","publishdate":"2010-04-02T13:05:52Z","relpermalink":"/blog/2010/04/02/one-line-statistics/","section":"post","summary":"Let\u0026rsquo;s assume we have a file with five columns where first column is text and rest of the columns are numeric. How can we calculate the standard deviation (or other statistical functions) with a perl one-liner?\nWe\u0026rsquo;ll use Statistics::Descriptive module.\nperl -MStatistics::Descriptive -ane 'BEGIN{our $stat = Statistics::Descriptive::Full-\u0026gt;new}; $stat-\u0026gt;add_data(@F[1..4]); print $stat-\u0026gt;standard_deviation,\u0026quot;\\n\u0026quot;; $stat-\u0026gt;clear' filename  $stat-\u0026gt;clear at the end was needed since data is added not assigned to $stat each time, so in order to prevent cumulative calculation, $stat variable should be cleared each time.","tags":["one-liner","perl"],"title":"One line statistics","type":"post"},{"authors":null,"categories":null,"content":"Maybe you already watched the video regarding Seadragon given at TED (sorry only low resolution version was available)\n  I just discovered that you can embed Seadragon into your own page. If you want to embed an image with enormous size, go to Seadragon page and paste URL of the image and it will create html embed script which you insert into your page\u0026rsquo;s html code.\nBelow is the Seadragon view of space image of world at night: (*EDIT: Since the seadragon page was very slow to respond, I just included the embed URL*S)\n\u0026lt;script src=\u0026quot;http://seadragon.com/embed/82q.js?width=auto\u0026amp;height=400px\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;  Original image is located here.\nHere\u0026rsquo;s another example (satellite image of Turkey):\n\u0026lt;script src=\u0026quot;http://seadragon.com/embed/yf4.js?width=auto\u0026amp;height=400px\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;  Original image is located here.\n","date":1270093800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1270093800,"objectID":"83653d99f9f0a46789de77033079d7a5","permalink":"/blog/2010/04/01/view-large-images-with-seadragon-in-personal-pages/","publishdate":"2010-04-01T03:50:00Z","relpermalink":"/blog/2010/04/01/view-large-images-with-seadragon-in-personal-pages/","section":"post","summary":"Maybe you already watched the video regarding Seadragon given at TED (sorry only low resolution version was available)\n  I just discovered that you can embed Seadragon into your own page. If you want to embed an image with enormous size, go to Seadragon page and paste URL of the image and it will create html embed script which you insert into your page\u0026rsquo;s html code.\nBelow is the Seadragon view of space image of world at night: (*EDIT: Since the seadragon page was very slow to respond, I just included the embed URL*S)","tags":["visualization"],"title":"View large images with Seadragon in personal pages","type":"post"},{"authors":null,"categories":null,"content":"Need a practical way to process fasta files with Bio::SeqIO module ? Below code will print sequence id and sequence length with tab per line.\nperl -MBio::SeqIO -e '$seq=Bio::SeqIO-\u0026gt;new(-fh =\u0026gt; \\*STDIN);while ($myseq=$seq-\u0026gt;next_seq){print $myseq-\u0026gt;id,\u0026quot;\\t\u0026quot;,$myseq-\u0026gt;length,\u0026quot;\\n\u0026quot;;}' \u0026lt; filename  OR\ncat filename | perl -MBio::SeqIO -e '$seq=Bio::SeqIO-\u0026gt;new(-fh =\u0026gt; \\*STDIN);while ($myseq=$seq-\u0026gt;next_seq){print $myseq-\u0026gt;id,\u0026quot;\\t\u0026quot;,$myseq-\u0026gt;length,\u0026quot;\\n\u0026quot;;}'  There are many more methods to use from Bio::Seq, such as revcom, translate, subseq(start,end), primary_id, desc, etc.\nPiped file does not need to be in Fasta format, there are many other formats (listed here) which SeqIO can parse successfully.\n UPDATE: If you are using this one-liner in a pipe, you might need to declare the format so that the stream is processed correctly. Also, in order to retrieve Bio::Seq methods, please use \u0026ldquo;-\u0026gt;seq\u0026rdquo; to access the final sequence.\nConsidering all these updates, the one-liner should look like this:\n perl -MBio::SeqIO -e '$seq=Bio::SeqIO-\u0026gt;new(-fh =\u0026gt; \\*STDIN,-format=\u0026gt;\u0026quot;fasta\u0026quot;);while ($myseq=$seq-\u0026gt;next_seq){print $myseq-\u0026gt;id,\u0026quot;\\t\u0026quot;,$myseq-\u0026gt;length,\u0026quot;\\t\u0026quot;,$myseq-\u0026gt;seq,\u0026quot;\\t\u0026quot;,$myseq-\u0026gt;translate-\u0026gt;seq,\u0026quot;\\n\u0026quot;;}'  ","date":1270089837,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1270089837,"objectID":"77af948bcf51ad2d0824516e27f68ef9","permalink":"/blog/2010/04/01/perl-one-liner-to-process-sequence-files-in-stream/","publishdate":"2010-04-01T02:43:57Z","relpermalink":"/blog/2010/04/01/perl-one-liner-to-process-sequence-files-in-stream/","section":"post","summary":"Need a practical way to process fasta files with Bio::SeqIO module ? Below code will print sequence id and sequence length with tab per line.\nperl -MBio::SeqIO -e '$seq=Bio::SeqIO-\u0026gt;new(-fh =\u0026gt; \\*STDIN);while ($myseq=$seq-\u0026gt;next_seq){print $myseq-\u0026gt;id,\u0026quot;\\t\u0026quot;,$myseq-\u0026gt;length,\u0026quot;\\n\u0026quot;;}' \u0026lt; filename  OR\ncat filename | perl -MBio::SeqIO -e '$seq=Bio::SeqIO-\u0026gt;new(-fh =\u0026gt; \\*STDIN);while ($myseq=$seq-\u0026gt;next_seq){print $myseq-\u0026gt;id,\u0026quot;\\t\u0026quot;,$myseq-\u0026gt;length,\u0026quot;\\n\u0026quot;;}'  There are many more methods to use from Bio::Seq, such as revcom, translate, subseq(start,end), primary_id, desc, etc.\nPiped file does not need to be in Fasta format, there are many other formats (listed here) which SeqIO can parse successfully.","tags":["bioinformatics","one-liner","perl"],"title":"perl one-liner to process sequence files in stream","type":"post"},{"authors":null,"categories":null,"content":"Very nice perl one-liner using map, sort and array range to show top ten occurrences\nTaken from Tech@Sakana blog\nperl -ane '$c{$F[0]}++; END {print map {$_ . \u0026quot;\\t-\u0026gt;\\t\u0026quot; . $c{$_} . \u0026quot;\\n\u0026quot;} (sort {$c{$b} \u0026lt;=\u0026gt; $c{$a}} keys %c)[0..9]}' filename  Same thing can be achieved by:\nsort filename | uniq -c | sort -nr | head  But the perl one-liner demonstrates the nice combination of sort and map.\n","date":1269957379,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1269957379,"objectID":"503d8633e83649476190b190a41072d6","permalink":"/blog/2010/03/30/top-ten-occurrences-with-perl-one-liner/","publishdate":"2010-03-30T13:56:19Z","relpermalink":"/blog/2010/03/30/top-ten-occurrences-with-perl-one-liner/","section":"post","summary":"Very nice perl one-liner using map, sort and array range to show top ten occurrences\nTaken from Tech@Sakana blog\nperl -ane '$c{$F[0]}++; END {print map {$_ . \u0026quot;\\t-\u0026gt;\\t\u0026quot; . $c{$_} . \u0026quot;\\n\u0026quot;} (sort {$c{$b} \u0026lt;=\u0026gt; $c{$a}} keys %c)[0..9]}' filename  Same thing can be achieved by:\nsort filename | uniq -c | sort -nr | head  But the perl one-liner demonstrates the nice combination of sort and map.","tags":["one-liner","perl"],"title":"Top ten occurrences with perl one-liner","type":"post"},{"authors":null,"categories":null,"content":"I really like one-liners which can do a lot in a single line.. I wanted to share one I just used to arrange a big table.\nIn the list of proteins below, only two proteins are shown, one protein has multiple attributes for 4 categories (InterPro, Cellular Component, Biological Process and Molecular Function). The other thing to notice is that, not all proteins have to have all the attributes, for instance, one protein might miss BiologicalProcess attribute.\n  protein1   Interpro   kinase     protein1   BiologicalProcess   protein folding     protein1   BiologicalProcess   metabolic process     protein1   MolecularFunction   DNA binding     protein1   CellularComponent   membrane     protein2   Interpro   transferase     protein2   Interpro   Methyltransferase     protein2   CellularComponent   membrane     protein2   CellularComponent   integral to membrane    Out of this table, I\u0026rsquo;m trying to get the following table:\n ProteinID  InterPro  Cellular Component  Biological Process  Molecular Function    protein1  kinase  membrane  protein folding; metabolic process  DNA binding    protein2  transferase; Methyltransferase  membrane; integral to membrane      Do you think this is possible with perl one-liner? Yes, it is..\nBelow is the code (suppose that Table 1 is in file called GeneCategories.txt\nperl -F\u0026quot;\\t\u0026quot; -ane 'chomp($F[2]); push @{$hash-\u0026gt;{$F[0]}-\u0026gt;{$F[1]}},$F[2]; END {foreach $id (sort keys %$hash){print $id,\u0026quot;\\t\u0026quot;; foreach $field qw(Interpro CellularComponent BiologicalProcess MolecularFunction){print join \u0026quot;;\u0026quot;,@{$hash-\u0026gt;{$id}-\u0026gt;{$field}}; print \u0026quot;\\t\u0026quot;;}; print \u0026quot;\\n\u0026quot;; } }' GeneCategories.txt  Let\u0026rsquo;s breakdown the code now. As we know, you can run perl code within terminal in this format:\nperl -e 'code'  If you want to run your code in a loop, then -n option should be used. In that case, either a filename should be provided or data should be piped to perl. Auto split can be turned on by -a option which will assign split elements to an array named @F.\nIf I don\u0026rsquo;t indicate that TAB is the separator, then SPACE or TAB is considered as separator. Since my data contains SPACE, I should specifically indicate that TAB is the separator by -F option.\nOne more thing about running perl in commandline with -n option. Suppose you wish to run additional code before and/or after the loop, then you should use the following format:\nperl -ne 'BEGIN {code1}; code2; END {code3}' filename  In this particular example, code1 will run before looping thru lines of filename and code3 will run after loop ended.\nOkay, now the meaning of the actual code:\nchomp($F[2])  Last column contains newline character at the end, I am removing it so that final output is not bad.\npush @{$hash-\u0026gt;{$F[0]}-\u0026gt;{$F[1]}},$F[2]  This is the core part where one protein can have multiple categories (Hash of hash) and one category can hold multiple values in an array (Hash of hash of array). Whatever is in third column is pushed into an array referred by hash of hash $hash-\u0026gt;{ProteinNo}-\u0026gt;{Category}\nAfter loop ended, hash structure is printed and mission accomplished..\n","date":1269481373,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1269481373,"objectID":"01e65e8ec84e82af7fef5a8c184eb883","permalink":"/blog/2010/03/25/perl-one-liner-to-change-table-layout-with-hash-of-hash-of-array/","publishdate":"2010-03-25T01:42:53Z","relpermalink":"/blog/2010/03/25/perl-one-liner-to-change-table-layout-with-hash-of-hash-of-array/","section":"post","summary":"I really like one-liners which can do a lot in a single line.. I wanted to share one I just used to arrange a big table.\nIn the list of proteins below, only two proteins are shown, one protein has multiple attributes for 4 categories (InterPro, Cellular Component, Biological Process and Molecular Function). The other thing to notice is that, not all proteins have to have all the attributes, for instance, one protein might miss BiologicalProcess attribute.","tags":["one-liner","perl"],"title":"perl one-liner to change table layout with Hash-of-Hash-of-Array","type":"post"},{"authors":null,"categories":null,"content":"I have been looking for a solution for broken bash_completion for scp command. I was thinking my ssh was not configured correctly for password-less login. But I just found out that bash completion is broken for Ubuntu 9.10.\nIf you are suffering from same symptom, please read this article for fix.\n","date":1268238603,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1268238603,"objectID":"825d7fc3da9959f6c7a5fb51149cb32d","permalink":"/blog/2010/03/10/bash-completion-for-scp/","publishdate":"2010-03-10T16:30:03Z","relpermalink":"/blog/2010/03/10/bash-completion-for-scp/","section":"post","summary":"I have been looking for a solution for broken bash_completion for scp command. I was thinking my ssh was not configured correctly for password-less login. But I just found out that bash completion is broken for Ubuntu 9.10.\nIf you are suffering from same symptom, please read this article for fix.","tags":["commandline","linux"],"title":"bash completion for scp","type":"post"},{"authors":null,"categories":null,"content":"Posting to WP from commandline is great. Before I post it, I need to lookup available categories so that I can categorize the new post correctly. To prevent a visit to WP admin GUI, I used the same Perl module for posting to retrieve available categories. Below is the code. I hope it helps you too..\nuse WordPress::XMLRPC; my $o = WordPress::XMLRPC-\u0026gt;new({ username =\u0026gt; 'username', password =\u0026gt; 'password', proxy =\u0026gt; 'http://yourblog-address/xmlrpc.php', }); my $categories= $o-\u0026gt;getCategories(); foreach (0..scalar(@$categories)) { print ${$categories}[$_]-\u0026gt;{'categoryId'},\u0026quot;\\t\u0026quot;,${$categories}[$_]-\u0026gt;{'categoryName'}; if (${$categories}[$_]-\u0026gt;{'parentId'} != 0){ print \u0026quot;\\tParentId=\u0026quot;,${$categories}[$_]-\u0026gt;{'parentId'},\u0026quot;\\n\u0026quot;; } else {print \u0026quot;\\n\u0026quot;} }  ","date":1263409695,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1263409695,"objectID":"981545b305b8cee1d2a94c20e3c7c478","permalink":"/blog/2010/01/13/retrieve-wp-categories-from-commandline/","publishdate":"2010-01-13T19:08:15Z","relpermalink":"/blog/2010/01/13/retrieve-wp-categories-from-commandline/","section":"post","summary":"Posting to WP from commandline is great. Before I post it, I need to lookup available categories so that I can categorize the new post correctly. To prevent a visit to WP admin GUI, I used the same Perl module for posting to retrieve available categories. Below is the code. I hope it helps you too..\nuse WordPress::XMLRPC; my $o = WordPress::XMLRPC-\u0026gt;new({ username =\u0026gt; 'username', password =\u0026gt; 'password', proxy =\u0026gt; 'http://yourblog-address/xmlrpc.","tags":["commandline","perl"],"title":"Retrieve WP categories from commandline","type":"post"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]